Linkuri Utile :
Hyper parameters SVM https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/


//GridShearc(parameri gama c si tipul de nuclue) PSD FFT
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_multilabel_classification
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import accuracy_score, classification_report
import seaborn as sns
from sklearn.metrics import multilabel_confusion_matrix
import matplotlib.pyplot as plt

# Generate synthetic multi-label dataset
X, y = make_multilabel_classification(n_samples=1000, n_features=20, n_classes=3, n_labels=2, random_state=42)
print(f"X content:{X[:5]}")
print(f"Y content:{y[:5]}")
# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the SVM model (wrapped in OneVsRestClassifier)
svm_model = OneVsRestClassifier(SVC())

# Define the hyperparameters and their possible values for tuning
param_grid = {
    'estimator__C': [0.1, 1, 10, 100],         # Regularization parameter
    'estimator__kernel': ['linear', 'rbf'],   # Kernel type
    'estimator__gamma': [1, 0.1, 0.01, 0.001, 0.0001] # Kernel coefficient for 'rbf' kernel
}

# Create GridSearchCV with the SVM model and hyperparameter grid
grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# Fit the grid search to the data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters from the grid search
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Get the best SVM model with the tuned hyperparameters
best_svm_model = grid_search.best_estimator_

# Make predictions on the test set
y_pred = best_svm_model.predict(X_test)

# Calculate accuracy on the test set
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy on Test Set:", accuracy)

# Print classification report
print("Classification Report:\n", classification_report(y_test, y_pred))

# Calculate and print average precision, recall, and F1-score
num_classes = y.shape[1]
avg_precision = np.mean([classification_report(y_test[:, i], y_pred[:, i], output_dict=True)['weighted avg']['precision'] for i in range(num_classes)])
avg_recall = np.mean([classification_report(y_test[:, i], y_pred[:, i], output_dict=True)['weighted avg']['recall'] for i in range(num_classes)])
avg_f1 = np.mean([classification_report(y_test[:, i], y_pred[:, i], output_dict=True)['weighted avg']['f1-score'] for i in range(num_classes)])

print("Average Precision:", avg_precision)
print("Average Recall:", avg_recall)
print("Average F1-Score:", avg_f1)
conf_matrices=multilabel_confusion_matrix(y_test, y_pred)
# Calculate and plot average confusion matrix
avg_conf_matrix = np.mean(conf_matrices, axis=0)
avg_conf_matrix = np.mean(conf_matrices, axis=0)
plt.figure(figsize=(5, 5))
sns.heatmap(avg_conf_matrix, annot=True, fmt=".2f", cmap="Blues", xticklabels=['0', '1'], yticklabels=['0', '1'])
plt.title('Average Confusion Matrix')
plt.show()

print(f"Your best parameter for svm are:\nbest_C={best_params['estimator__C']}\nbest_kernel={best_params['estimator__kernel']}\nbest_gamma={best_params['estimator__gamma']}")
//GridShearc(parameri gama c si tipul de nuclue) MFCC

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_multilabel_classification
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import accuracy_score, classification_report
import seaborn as sns
from sklearn.metrics import multilabel_confusion_matrix
import matplotlib.pyplot as plt

# Generate synthetic multi-label dataset with X having 40 rows and 3050 columns
X, y = make_multilabel_classification(
    n_samples=1000, n_features=3050, n_classes=3, n_labels=2, random_state=42
)

# Take the first 40 rows from X and y
X = X[:40, :]
y = y[:40, :]

print(f"X shape: {X.shape}")
print(f"Y shape: {y.shape}")

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the SVM model (wrapped in OneVsRestClassifier)
svm_model = OneVsRestClassifier(SVC())

# Define the hyperparameters and their possible values for tuning
param_grid = {
    'estimator__C': [0.1, 1, 10, 100],         # Regularization parameter
    'estimator__kernel': ['linear', 'rbf'],   # Kernel type
    'estimator__gamma': [1, 0.1, 0.01, 0.001, 0.0001] # Kernel coefficient for 'rbf' kernel
}

# Create GridSearchCV with the SVM model and hyperparameter grid
grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)

# Fit the grid search to the data
grid_search.fit(X_train, y_train)

# Get the best hyperparameters from the grid search
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Get the best SVM model with the tuned hyperparameters
best_svm_model = grid_search.best_estimator_

# Make predictions on the test set
y_pred = best_svm_model.predict(X_test)

# Calculate accuracy on the test set
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy on Test Set:", accuracy)

# Print classification report
report = classification_report(y_test, y_pred, output_dict=True)
print("Classification Report:\n", classification_report(y_test, y_pred))

# Calculate and print average precision, recall, and F1-score
num_classes = y.shape[1]  # Add this line to initialize num_classes
avg_precision = np.mean([report[str(i)]['precision'] for i in range(num_classes)])
avg_recall = np.mean([report[str(i)]['recall'] for i in range(num_classes)])
avg_f1 = np.mean([report[str(i)]['f1-score'] for i in range(num_classes)])

print("Average Precision:", avg_precision)
print("Average Recall:", avg_recall)
print("Average F1-Score:", avg_f1)

# Plot average confusion matrix heatmap
avg_conf_matrix = np.mean(multilabel_confusion_matrix(y_test, y_pred), axis=0)

# Convert the float values in the matrix to integers for formatting
avg_conf_matrix = avg_conf_matrix.astype(int)

plt.figure(figsize=(5, 5))
sns.heatmap(avg_conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=['0', '1'], yticklabels=['0', '1'])
plt.title('Average Confusion Matrix')

plt.show()
print(f"Your best parameter for svm are:\nbest_C={best_params['estimator__C']}\nbest_kernel={best_params['estimator__kernel']}\nbest_gamma={best_params['estimator__gamma']}")


Imagine fundal paret superrioara :
https://www.bing.com/images/search?view=detailV2&ccid=fOSUrAHX&id=2666D0D643173EDEC406D8982E0273E2322762E4&thid=OIP.fOSUrAHXwJ062sGbj6SZEgHaEo&mediaurl=https%3A%2F%2Frestomods.com%2Fwp-content%2Fuploads%2F2017%2F02%2Fchevelleburnout2-1.jpg&cdnurl=https%3A%2F%2Fth.bing.com%2Fth%2Fid%2FR.7ce494ac01d7c09d3adac19b8fa49912%3Frik%3D5GInMuJzAi6Y2A%26pid%3DImgRaw%26r%3D0&exph=1000&expw=1600&q=cars+burning+out&simid=608008979902443530&form=IRPRST&ck=264FB96F7D3FBB62C867BFA3FFAE5E12&selectedindex=2&itb=0&ajaxhist=0&ajaxserp=0&vt=0&sim=11
Imagone page1 main whit info abaout us 
https://www.bing.com/images/search?view=detailV2&ccid=%2bT4ixjTL&id=2B91354FA4ADFF425361D07C7B32956D1B8A534E&thid=OIP.-T4ixjTLjDQaXyvaulRUUgHaFq&mediaurl=https%3a%2f%2fwww.lucidsamples.com%2fblog%2fwp-content%2fuploads%2f2018%2f01%2fAdobeStock_6525764.jpeg&cdnurl=https%3a%2f%2fth.bing.com%2fth%2fid%2fR.f93e22c634cb8c341a5f2bdaba545452%3frik%3dTlOKG22VMnt80A%26pid%3dImgRaw%26r%3d0&exph=5200&expw=6800&q=sound+waves+&simid=607996365606184426&FORM=IRPRST&ck=9C97C094E3ED13B79F393CC2E92CC7E1&selectedIndex=17&itb=0&ajaxhist=0&ajaxserp=0
Incearca s adaptezi pentru grid shearch hai ca se poate 
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.multiclass import OneVsRestClassifier

# Generare set de date simplu
data=np.array([np.array([np.random.rand() for j in range(200)]) for i in range(100)])
target=np.array([np.array([np.random.randint(100)%2 for j in range(32)]) for i in range(100)] )
print(f"Data shape is equal whit {data.shape}")
print(f"Target shape is equal whit {target.shape}")
# Definirea parametrilor pentru căutarea pe grilă
param_grid = {'estimator__C': [1, 10, 100], 'estimator__gamma': [0.1, 0.01, 0.001,0.0001]}

# Inițierea clasificatorului SVM
svm =  OneVsRestClassifier(SVC(kernel='rbf'))

# Inițierea căutării pe grilă
grid_search =GridSearchCV(svm, param_grid, cv=5)
grid_search.fit(data, target)

# Extrage rezultatele
cv_results = grid_search.cv_results_

# Vizualizare diagramă de contur pentru parametrul gamma
plt.figure(figsize=(10, 8))

# Creare grid pentru gamma și C
gamma_values = np.array(param_grid['estimator__gamma'])
C_values = np.array(param_grid['estimator__C'])
gamma_values, C_values = np.meshgrid(gamma_values, C_values)

# Plasare diagramă de contur în funcție de performanța modelului pentru fiecare combinație gamma-C
contour = plt.contour(np.log10(gamma_values), np.log10(C_values), cv_results['mean_test_score'].reshape(len(param_grid['estimator__C']), -1), cmap='viridis')

# Adăugare bară de culoare
plt.colorbar(contour, label='Mean Test Score')

# Etichete și titlu
plt.xlabel('log10(gamma)')
plt.ylabel('log10(C)')
plt.title('Efectul parametrului gamma în căutarea pe grilă')

# Afișare diagramă
plt.show()
Buna ziua ! Sigur am sa lucrez la slide-uri si o sa fie gata in weekend.
Iar referitor la perioada de inscriere si prezentare conform linkului acesta 
https://absolvire.info.uaic.ro/
Structura este urmatoarea :
Preînscriere: online, 2-8 februarie 2024 (se aleg cele 4 materi si se ofera documente legislative)
Înscriere: online, 10-15 februarie 2024 (trebuie data varainat scrisa a lucrari si alte resurse cod,bazadedate,slide-uri etc)
Verificare dosare de către secretariat: 2-16 februarie 2024
Susținerea lucrării de licență: 19-25 februarie 2024 – a se vedea programarea pe comisii la secțiunea 7
Afișarea rezultatelor – în ziua examenului
